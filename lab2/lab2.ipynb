{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "id": "5b31d12097874d"
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql.functions import year, to_timestamp\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Создание сессии Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"yarl_lab_2\") \\\n",
    "    .getOrCreate()"
   ],
   "id": "5b31d12097874d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "f99118016f5e4699",
    "outputId": "0a8df2a7-2eaf-4785-ec10-70e06e3fc4ce",
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "tree = ET.parse(\"posts_sample.xml\")\n",
    "root = tree.getroot()\n",
    "data = []\n",
    "\n",
    "# Парсим xml файл\n",
    "for row in root.findall('row'):\n",
    "  # Получаем нужные поля\n",
    "    date = row.attrib.get('CreationDate')\n",
    "    tags = row.attrib.get('Tags')\n",
    "    if tags is not None:\n",
    "        # Т.к. в тэге поста может много языков - удаляем лишние символы и разбиваем на массив тэгов\n",
    "        tags = tags.replace('<', '').replace('>', ' ').strip().split()\n",
    "        for tag in tags:\n",
    "            data.append((date, tag))\n",
    "\n",
    "data"
   ],
   "id": "f99118016f5e4699",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Создание схемы DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"CreationDate\", StringType(), True),\n",
    "    StructField(\"Tag\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Создание DataFrame\n",
    "xml_df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Извлекаем год из доты\n",
    "xml_df = xml_df.withColumn(\"Year\", year(to_timestamp(xml_df[\"CreationDate\"], \"yyyy-MM-dd'T'HH:mm:ss.SSS\")))\n",
    "\n",
    "# Дропаем ненужный столбец\n",
    "xml_df = xml_df.drop(\"CreationDate\")\n",
    "\n",
    "xml_df.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvtD74FZpE7S",
    "outputId": "1f9926a7-aaac-4055-b1ce-d64f5f337c19",
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "OvtD74FZpE7S",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "schema = StructType([\n",
    "    StructField(\"Tag\", StringType(), True),\n",
    "    StructField(\"wikipedia_url\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Читаем CSV файл в DataFrame\n",
    "csv_df = spark.read.csv(\"programming-languages.csv\", schema=schema)\n",
    "\n",
    "# Добавляем индекс к DataFrame\n",
    "csv_df = csv_df.rdd.zipWithIndex().toDF([\"data\", \"index\"])\n",
    "\n",
    "# Извлекаем данные обратно в DataFrame\n",
    "csv_df = csv_df.filter(csv_df.index != 0).select(\"data.*\")\n",
    "\n",
    "from pyspark.sql.functions import lower\n",
    "\n",
    "csv_df = csv_df.withColumn(\"Tag\", lower(csv_df[\"Tag\"]))\n",
    "\n",
    "csv_df.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pVYvPwzZ4WGQ",
    "outputId": "eb9af0d6-7c42-424c-c8ba-ffb7052dfe37",
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "pVYvPwzZ4WGQ",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Джоиним таблицы, чтобы убрать теги без языков программирования\n",
    "df = xml_df.join(csv_df, on=\"Tag\", how=\"inner\")\n",
    "df = df.drop(\"wikipedia_url\")\n",
    "\n",
    "df.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJmhy9b3MyaW",
    "outputId": "d82b59ab-f6c2-4e74-ea72-ba07c5fe1f9a",
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "nJmhy9b3MyaW",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "# Группируем по году и языку, считаем количество упоминаний\n",
    "language_counts = df.groupBy(\"Tag\", \"Year\").count()\n",
    "\n",
    "# Определяем окно для ранжирования\n",
    "window_spec = Window.partitionBy(\"Year\").orderBy(F.desc(\"count\"))\n",
    "\n",
    "# Добавляем ранг и фильтруем топ-10 языков для каждого года\n",
    "top_languages = language_counts.withColumn(\"rank\", F.row_number().over(window_spec)) \\\n",
    "    .filter(F.col(\"rank\") <= 10) \\\n",
    "    .drop(\"rank\")\n",
    "\n",
    "top_languages = top_languages.orderBy(\"Year\", F.desc(\"count\"))\n",
    "\n",
    "# Сохраняем результат в формате Parquet\n",
    "top_languages.write.mode(\"overwrite\").parquet(\"top_10_languages_by_year.parquet\")\n"
   ],
   "metadata": {
    "id": "t9K7WYdFNbmE",
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "t9K7WYdFNbmE",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
